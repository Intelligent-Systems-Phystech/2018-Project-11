\documentclass[12pt,twoside]{article}


\usepackage{graphicx}
\usepackage{caption}
\usepackage{footnote}
\usepackage{jmlda}


\begin{document}

\title
    {Автоматическое построение нейросети оптимальной сложности}
\author
    {Горян$^1$~Н.\,А. Бахтеев$^1$~О.\,Ю.  Стрижов$^2$~В.\,В.} % основной список авторов, выводимый в оглавление

\organization
    {$^1$Московский физико-технический институт\par
    $^2$Вычислительный центр им. А.~А. Дородницына ФИЦ ИУ РАН}

\email
    {goryan.na@phystech.edu; bakhteev@phystech.edu; strijov@phystech.edu}    


    

\abstract
	{Работа посвящена выбору оптимальной модели нейронной сети. Нейронная сеть рассматривается как вычислительный граф, рёбра которого --- примитивные функции, а вершины --- промежуточные представления выборки. Предполагается, что структуру нейронной сети можно упростить без значимой потери качества классификации. Структура нейросети опеределяется вершинами симплекса. Для определения нужной структуры нейронной сети предлагается проводить оптимизацию гиперпараметров и структурных параметров. Для решения задачи оптимизации предлагается проводить релаксацию структуры. Для анализа качества представленного алгоритма проводятся эксперименты на выборках Boston, MNIST и CIFAR-10.
\bigskip

\textbf{Ключевые слова}: \emph {нейронные сети, оптимизация гиперпараметров, прореживание нейронной сети, оптимальная структура нейронной сети, вариационный вывод}.
}


\maketitle


\section{ Введение}
	Существует много способов и приёмов построения нейронных сетей для различных сфер деятельности. Но не смотря на огромное количество усилий, приложенных в этой области человечеством, известно очень мало эффективных
	способов построения оптимальных нейросетей. Дело в том, что для того чтобы подобрать нужную сеть требуется узнать её гиперпараметры~\cite{Myung1997}: количество слоёв, нейронов в каждом слое и функции активации каждого нейрона. А подбор этих параметров является вычислительно сложной задачей~\cite{sutskever2014}.
	
	Есть несколько подходов построения оптимальной сети. В работе ~\cite{cun1990, graves2011} используется метод прореживания нейросети. Он заключается в том, что строится заведомо переусложнённая модель, которая в последствии упрощается. Ещё одиним способом, предложенным в работе ~\cite{Maclaurin:2015:GHO:3045118.3045343}, является метаобучение. В его основе лежит идея того, что заранее обученная нейронная сеть строит по входным данным требуемую нейросеть.
	
	Данная работа посвящена методу построения построения оптимальной нейронной сети подбором гиперпараметров в одной процедуре. В основе метода лежит алгоритм DARTS, предложенным в работе ~\cite{liu2018darts}. Входными данными метода являются являются некоторый набор данных и заранее определённый набор функций активации. Как результат мы получаем оптимальную нейросеть.
	
	Проверка и анализ метода проводится на выборке Boston Housing~\cite{Boston}, MNIST~\cite{MNIST},  CIFAR-10 ~\cite{CIFAR-10} и синтетических данных. Результат сравнивается с моделью, полученной при помощи базовых алгоритмов.
	 

\cite{bishop2006}

\bibliographystyle{unsrt}
\bibliography{Goryan2018Project11}
\end{document}
